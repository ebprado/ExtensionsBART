dtpois(num_cov, a = 0, b = trunc[j], lambda=lambda[i])))
}
}
}
save_prior_num_cov_t = as.data.frame(save_prior_num_cov_t)
names(save_prior_num_cov_t)[-c(1:3)] = paste('c',num_cov, sep='')
write.csv(save_prior_num_cov_t, '/Users/estevaoprado/OneDrive - Maynooth University/PhD_Stats_Maynooth/GLM_BART/GAM_BART/prior_num_cov.csv')
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.3, one_var_per_tree = FALSE, nburn = 100, npost = 100)
library(GAMbart)
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.3, one_var_per_tree = FALSE, nburn = 100, npost = 100)
f = function(x){
10*sin(pi*x[,1]*x[,2]) + 20*(x[,3]-.5)^2+10*x[,4]+5*x[,5]
}
sigma = 1.0  #y = f(x) + sigma*z , z~N(0,1)
n = 100      #number of observations
set.seed(99)
x=matrix(runif(n*10),n,10) #10 variables, only first 5 matter
Ey = f(x)
y=Ey+sigma*rnorm(n)
lmFit = lm(y~.,data.frame(x,y)) #compare lm fit to BART later
plot(y, lmFit$fitted.values); abline(0,1, col=2)
##test BART with token run to ensure installation works
library(BART)
set.seed(99)
bartFit = wbart(x,y,sparse = TRUE, power = 2, base = 0.05)
plot(y, bartFit$yhat.train.mean); abline(0,1)
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.3, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0, one_var_per_tree = FALSE, nburn = 100, npost = 100)
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.001, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.0001, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]][[1]]
gambart.fit2$trees[[100]]
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.001, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]]
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 1, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]]
0
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.1, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]]
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.5, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]]
gambart.fit2$trees[[100]]
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.0005, one_var_per_tree = FALSE, nburn = 100, npost = 100)
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.0005, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]]
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 5, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]]
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 15, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]]
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 2, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]]
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.0002, one_var_per_tree = FALSE, nburn = 100, npost = 100)
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.0002, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]]
install.packages("COMPoissonReg")
## COM-Poisson
library(COMPoissonReg)
curve(dcmp(x, 2, 1))
curve(dcmp(x, 2, 1), 0, 2)
curve(dcmp(x, 2, 1), 0, 5)
curve(dcmp(x, 2, 0.5), 0, 5, add=TRUE)
curve(dcmp(x, 2, 0.25), 0, 5, add=TRUE)
curve(dcmp(x, 2, 0.5), 0, 5, add=TRUE, col=2)
curve(dcmp(x, 2, 1), 0, 5)
curve(dcmp(x, 2, 0.5), 0, 5, add=TRUE, col=2)
curve(dcmp(x, 2, 0.25), 0, 5, add=TRUE, col=3)
curve(dcmp(x, 2, 0.25), 0, 5)
curve(dcmp(x, 2, 0.25), 0, 10), add=TRUE, col=3)
curve(dcmp(x, 2, 0.25), 0, 10)
curve(dcmp(x, 2, 0.25), 0, 20)
curve(dcmp(x, 2, 1), 0, 5)
curve(dcmp(x, 2, 0.25), 0, 20), add=TRUE, col=3)
curve(dcmp(x, 2, 0.25), 0, 20), add=TRUE, col=3)
curve(dcmp(x, 2, 0.25), 0, 20, add=TRUE, col=3)
curve(dcmp(x, 2, 0.25), 0, 20)
curve(dcmp(x, 2, 0.3), 0, 20)
curve(dcmp(x, 2, 1), 0, 5)
curve(dcmp(x, 2, 0.5), 0, 5, add=TRUE, col=2)
curve(dcmp(x, 2, 0.3), 0, 5), add=TRUE, col=3)
curve(dcmp(x, 2, 0.3), 0, 5, add=TRUE, col=3)
curve(dcmp(x, 2, 1), 0, 10)
curve(dcmp(x, 2, 0.5), 0, 10, add=TRUE, col=2)
curve(dcmp(x, 2, 0.3), 0, 10, add=TRUE, col=3)
curve(dcmp(x, 2, 1.5), 0, 10, add=TRUE, col=3)
curve(dcmp(x, 2, 1), 0, 10)
curve(dcmp(x, 2, 0.5), 0, 10, add=TRUE, col=2)
curve(dcmp(x, 2, 0.3), 0, 10, add=TRUE, col=3)
curve(dcmp(x, 2, 1.5), 0, 10, add=TRUE, col=4)
curve(dcmp(x, 2, 2), 0, 10, add=TRUE, col=4)
curve(dcmp(x, 2, 3), 0, 10, add=TRUE, col=4)
curve(dcmp(x, 2, 1), 0, 10)
curve(dcmp(x, 2, 3), 0, 10, add=TRUE, col=2)
curve(dcmp(x, 2, 1.5), 0, 10, add=TRUE, col=2)
curve(dcmp(x, 2, 1), 0, 10)
curve(dcmp(x, 2, 1.5), 0, 10, add=TRUE, col=2)
curve(dcmp(x, 2, 1.5), 0, 10)
curve(dcmp(x, 2, 1.5), 0, 10, col=2)
curve(dcmp(x, 2, 1), 0, 10, add=TRUE)
curve(dcmp(x, 2, 3), 0, 10, col=3)
curve(dcmp(x, 2, 1.5), 0, 10, col=2, col=TRUE)
curve(dcmp(x, 2, 3), 0, 10, col=3)
curve(dcmp(x, 2, 1.5), 0, 10, col=2, add=TRUE)
curve(dcmp(x, 2, 1), 0, 10, add=TRUE)
curve(dcmp(x, 2, 5), 0, 10, col=4)
curve(dcmp(x, 2, 3), 0, 10, col=3, add=TRUE)
curve(dcmp(x, 2, 1.5), 0, 10, col=2, add=TRUE)
curve(dcmp(x, 2, 1), 0, 10, add=TRUE)
curve(dcmp(x, 2, 10), 0, 10, col=5)
curve(dcmp(x, 2, 5), 0, 10, col=4, add=TRUE)
curve(dcmp(x, 2, 20), 0, 10, col=5)
curve(dcmp(x, 2, 5), 0, 10, col=4, add=TRUE)
curve(dcmp(x, 2, 3), 0, 10, col=3, add=TRUE)
curve(dcmp(x, 2, 1.5), 0, 10, col=2, add=TRUE)
curve(dcmp(x, 2, 1), 0, 10, add=TRUE)
## COM-Poisson
library(COMPoissonReg)
curve(dcmp(x, 2, 1), 0, 10)
curve(dcmp(x, 2, 0.5), 0, 10, add=TRUE, col=2)
curve(dcmp(x, 2, 0.3), 0, 10, add=TRUE, col=3)
curve(dcmp(x, 2, 20), 0, 10, col=5)
curve(dcmp(x, 2, 20, log=TRUE), 0, 10, col=5)
curve(dcmp(x, 2, 5, log=TRUE), 0, 10, col=4, add=TRUE)
curve(dcmp(x, 2, 3, log=TRUE), 0, 10, col=3, add=TRUE)
curve(dcmp(x, 2, 1.5, log=TRUE), 0, 10, col=2, add=TRUE)
curve(dcmp(x, 2, 1, log=TRUE), 0, 10, add=TRUE)
dcmp(0:10, 2, 5, log=TRUE)
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 0.0002, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]]
set.seed(001)
gambart.fit2 = gam_bart(x,y, str='original', penalty_add_cov = TRUE, penalty_lambda = 2, one_var_per_tree = FALSE, nburn = 100, npost = 100)
plot(y, apply(gambart.fit2$y_hat,2,mean)); abline(0,1, col=2)
cor(y, apply(gambart.fit2$y_hat,2,mean))
gambart.fit2$trees[[100]]
w = rnorm(n, 0,1)
y = rbinom(n,1,0.5)
y==0
n = 100
w = rnorm(n, 0,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z
z = ifelse(w[y==0] < 0, w, 0)
z
z = rep(NA,n)
z
z[y==0] = ifelse(w[y==0] < 0, w, 0)
z
n = 100
w = rnorm(n, 0,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w, 0)
z[y==1] = ifelse(w[y==1] > 0, w, 0)
hist(z)
z
n = 100
w = rnorm(n, 0,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w, 0)
z[y==1] = ifelse(w[y==1] > 0, w, 0)
hist(z)
library(truncnorm)
length(y==0)
y==0
sum(y==0)
ny1 = sum(y==1)
ny1
n = 100
w = rnorm(n, 0,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = 0, 1)
z[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = 0, 1)
hist(z)
z
y==0
n = 100
w = rnorm(n, 0,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z[y==0] = pmin(w[y==0], 0)
z[y==1] = pmax(w[y==1], 0)
hist(z)
w
hist(w)
n = 100
w = rnorm(n, 0,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = 0, 1)
z[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = 0, 1)
hist(z)
n = 100
n = 100
w = rnorm(n, 0,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = w[y==0], 1)
z[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = w[y==1], 1)
hist(z)
z
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w, 0)
z[y==1] = ifelse(w[y==1] > 0, w, 0)
hist(z)
z
w[y==0]
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
y==0
ifelse(w[y==0] < 0, w[y==0], 0)
sum(y==0)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z
ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
ny0 = sum(y==0)
set.seed(001)
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
n = 100
set.seed(001)
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
set.seed(001)
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
n = 100
z = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = fx[y==0], 1)
z[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = fx[y==1], 1)
hist(z)
z
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
y = rbinom(n,1,0.5)
set.seed(001)
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
z = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = fx[y==0], 1)
z[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = fx[y==1], 1)
hist(z)
z = rep(NA,n)
z = rep(NA,n)
z = rep(NA,n)
z[y==0] = pmin(w[y==0], 0)
z[y==1] = pmax(w[y==1], 0)
hist(z)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
z = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = fx[y==0], 1)
z[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = fx[y==1], 1)
hist(z)
z
set.seed(001)
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
z
z3 = rep(NA,n)
z3[y==0] = pmin(w[y==0], 0)
z3[y==1] = pmax(w[y==1], 0)
hist(z3)
z2 = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z2[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = fx[y==0], 1)
z2[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = fx[y==1], 1)
hist(z2)
z2
# The way the referee understood our algorithm
set.seed(001)
n = 100
fx = rnorm(n, 0, 2)
w = rnorm(n, fx,1)
y = rbinom(n,1,0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
set.seed(001)
n = 100
fx = rnorm(n, 0, 2) # sum of the trees
w = rnorm(n, fx, 1)
y = rbinom(n, 1, 0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
z
z2 = rep(NA,n)
z2[y==0] = pmin(w[y==0], 0)
z2[y==1] = pmax(w[y==1], 0)
hist(z2)
z2
z3 = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z3[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = fx[y==0], 1)
z3[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = fx[y==1], 1)
hist(z3)
z3
z3 = rep(NA,n)
ny0 = sum(y==0)
z3
z3 = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z3[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = fx[y==0], 1)
z3[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = fx[y==0], 1)
z3[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = fx[y==1], 1)
hist(z3)
z3
# The way the referee understood our algorithm
set.seed(001)
n = 100
fx = rnorm(n, 0, 2) # sum of the trees
w = rnorm(n, fx, 1)
y = rbinom(n, 1, 0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
## The way is implemented in R
z2 = rep(NA,n)
z2[y==0] = pmin(w[y==0], 0)
z2[y==1] = pmax(w[y==1], 0)
hist(z2)
### Albert and Chib (1993)
z3 = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z3[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = fx[y==0], 1)
z3[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = fx[y==1], 1)
hist(z3)
z3
# The way the referee understood our algorithm
set.seed(001)
n = 100
fx = rnorm(n, 0, 2) # sum of the trees
w = rnorm(n, fx, 1)
y = rbinom(n, 1, 0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
## The way is implemented in R
z2 = rep(NA,n)
z2[y==0] = pmin(w[y==0], 0)
z2[y==1] = pmax(w[y==1], 0)
hist(z2)
### Albert and Chib (1993)
z3 = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z3[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = fx[y==0], 1)
z3[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = fx[y==1], 1)
hist(z3)
z3
fx[y==0]
ny0
install()
library(devtools)
install()
load_all()
document()
check()
# The way the referee understood our algorithm
set.seed(001)
n = 100
fx = rnorm(n, 0, 2) # sum of the trees
w = rnorm(n, fx, 1)
y = rbinom(n, 1, 0.5)
z = rep(NA,n)
z[y==0] = ifelse(w[y==0] < 0, w[y==0], 0)
z[y==1] = ifelse(w[y==1] > 0, w[y==1], 0)
hist(z)
z
z2 = rep(NA,n)
z2[y==0] = pmin(w[y==0], 0)
z2[y==1] = pmax(w[y==1], 0)
hist(z2)
z3 = rep(NA,n)
ny0 = sum(y==0)
ny1 = sum(y==1)
z3[y==0] = rtruncnorm(ny0, a = -Inf, b=0, mean = fx[y==0], 1)
z3[y==1] = rtruncnorm(ny1, a = 0, b=Inf, mean = fx[y==1], 1)
hist(z3)
z3
install_github("ebprado/MOTR-BART/GAMbart")
library(devtools)
install_github("ebprado/MOTR-BART/GAMbart")
library(GAMbart)
# Simulate a Friedman data set
friedman_data = function(n, num_cov, sd_error){
x = matrix(runif(n*num_cov),n,num_cov)
y = 10*sin(pi*x[,1]*x[,2]) + 20*(x[,3]-.5)^2+10*x[,4]+5*x[,5] + rnorm(n, sd=sd_error)
return(list(y = y,
x = x))
}
# Training data
data = friedman_data(200, 10, 1)
y = data$y
x = data$x
# Test data
data_test = friedman_data(100, 10, 1)
y.test = data_test$y
x.test = data_test$x
# Run GAM-BART
set.seed(99)
fit.gam.bart = gam_bart(x, y, str = 'original', ntrees = 10, nburn = 1000, npost = 100, df=5, dg=3, ancestors = FALSE, penalty = 'ridge')
fit.gam.bart = gam_bart(x, y, str = 'original', ntrees = 10, nburn = 100, npost = 100, df=5, dg=3, ancestors = FALSE, penalty = 'ridge')
plot(y,apply(fit.gam.bart$y_hat,2,mean));abline(0,1)
fit.gam.bart$trees[[100]]
