return(new_tree)
} # End of prune_tree function
# change_tree function ----------------------------------------------------
change_tree = function(X, y, curr_tree, node_min_size) {
# Change a node means change out the split value and split variable of an internal node. Need to make sure that this does now produce a bad tree (i.e. zero terminal nodes)
# If current tree is a stump nothing to change
if(nrow(curr_tree$tree_matrix) == 1) {
curr_tree$var = c(0, 0)
return(curr_tree)
}
# Create a holder for the new tree
new_tree = curr_tree
# Need to get the internal nodes
internal_nodes = which(as.numeric(new_tree$tree_matrix[,'terminal']) == 0)
terminal_nodes = which(as.numeric(new_tree$tree_matrix[,'terminal']) == 1)
# Create a while loop to get good trees
# Create a counter to stop after a certain number of bad trees
max_bad_trees = 2
count_bad_trees = 0
bad_trees = TRUE
while(bad_trees) {
# Re-set the tree
new_tree = curr_tree
# choose an internal node to change
node_to_change = sample(internal_nodes, 1)
# Get the covariate that will be changed
var_changed_node = as.numeric(new_tree$tree_matrix[node_to_change, 'split_variable'])
# Use the get_children function to get all the children of this node
all_children = get_children(new_tree$tree_matrix, node_to_change)
# Now find all the nodes which match these children
use_node_indices = !is.na(match(new_tree$node_indices, all_children))
# Create new split variable and value based on ignorance
# then check this doesn't give a bad tree
available_values = NULL
new_split_variable = sample(1:ncol(X), 1)
available_values = sort(unique(X[use_node_indices,
new_split_variable]))
if (length(available_values) == 1){
new_split_value = available_values[1]
new_tree$var = c(var_changed_node, new_split_variable)
} else if (length(available_values) == 2){
new_split_value = available_values[2]
new_tree$var = c(var_changed_node, new_split_variable)
} else {
# new_split_value = sample(available_values[-c(1,length(available_values))], 1)
new_split_value = resample(available_values[-c(1,length(available_values))])
}
# Update the tree details
new_tree$tree_matrix[node_to_change,
c('split_variable',
'split_value')] = c(new_split_variable,
new_split_value)
# Update the tree node indices
new_tree = fill_tree_details(new_tree, X)
# Store the covariate name that was used in the splitting rule of the terminal node that was just changed
new_tree$var = c(var_changed_node, new_split_variable)
# Check for bad tree
if(any(as.numeric(new_tree$tree_matrix[terminal_nodes, 'node_size']) <= node_min_size)) {
count_bad_trees = count_bad_trees + 1
} else {
bad_trees = FALSE
}
if(count_bad_trees == max_bad_trees){
curr_tree$var = c(0, 0)
return(curr_tree)
}
} # end of while loop
# Return new_tree
return(new_tree)
} # End of change_tree function
# swap_tree function ------------------------------------------------------
swap_tree = function(X, y, curr_tree, node_min_size) {
# Swap takes two neighbouring internal nodes and swaps around their split values and variables
# If current tree is a stump nothing to change
if(nrow(curr_tree$tree_matrix) == 1) return(curr_tree)
# Create a holder for the new tree
new_tree = curr_tree
# Need to get the internal nodes
internal_nodes = which(as.numeric(new_tree$tree_matrix[,'terminal']) == 0)
terminal_nodes = which(as.numeric(new_tree$tree_matrix[,'terminal']) == 1)
# If less than 3 internal nodes return curr_tree
if(length(internal_nodes) < 3) return(curr_tree)
# Find pairs of neighbouring internal nodes
parent_of_internal = as.numeric(new_tree$tree_matrix[internal_nodes,'parent'])
pairs_of_internal = cbind(internal_nodes, parent_of_internal)[-1,]
# Create a while loop to get good trees
# Create a counter to stop after a certain number of bad trees
max_bad_trees = 2
count_bad_trees = 0
bad_trees = TRUE
while(bad_trees) {
# Re-set the tree
new_tree = curr_tree
# Pick a random pair
nodes_to_swap = sample(1:nrow(pairs_of_internal), 1)
# Get the split variables and values for this pair
swap_1_parts = as.numeric(new_tree$tree_matrix[pairs_of_internal[nodes_to_swap,1],
c('split_variable', 'split_value')])
swap_2_parts = as.numeric(new_tree$tree_matrix[pairs_of_internal[nodes_to_swap,2],
c('split_variable', 'split_value')])
# Update the tree details - swap them over
new_tree$tree_matrix[pairs_of_internal[nodes_to_swap,1],
c('split_variable',
'split_value')] = swap_2_parts
new_tree$tree_matrix[pairs_of_internal[nodes_to_swap,2],
c('split_variable',
'split_value')] = swap_1_parts
# Update the tree node indices
new_tree = fill_tree_details(new_tree, X)
# Check for bad tree
if(any(as.numeric(new_tree$tree_matrix[terminal_nodes, 'node_size']) <= node_min_size)) {
count_bad_trees = count_bad_trees + 1
} else {
bad_trees = FALSE
}
if(count_bad_trees == max_bad_trees) return(curr_tree)
} # end of while loop
# Return new_tree
return(new_tree)
} # End of swap_tree function
# -------------------------------------------------------------------------#
# Description: this script contains 2 functions that are used to generate  #
#              the predictions, update variance and compute the tree prior #
#              and the marginalised likelihood                             #
# -------------------------------------------------------------------------#
# 1. simulate_mu: generate the predicted values (mu's)
# 2. update_sigma2: updates the parameters sigma2
# 3. update_z: updates the latent variables z. This is required for MOTR-BART for classification.
# 4. get_tree_prior: returns the tree log prior score
# 5. tree_full_conditional: computes the marginalised likelihood for all nodes for a given tree
# 6. get_number_distinct_cov: counts the number of distinct covariates that are used in a tree to create the splitting rules
# Compute the full conditionals -------------------------------------------------
tree_full_conditional = function(tree, R, sigma2, sigma2_mu) {
# Function to compute log full conditional distirbution for an individual tree
# R is a vector of partial residuals
# Need to calculate log complete conditional, involves a sum over terminal nodes
# First find which rows are terminal nodes
which_terminal = which(tree$tree_matrix[,'terminal'] == 1)
# Get node sizes for each terminal node
nj = tree$tree_matrix[which_terminal,'node_size']
# Get sum of residuals and sum of residuals squared within each terminal node
sumRsq_j = aggregate(R, by = list(tree$node_indices), function(x) sum(x^2))[,2]
S_j = aggregate(R, by = list(tree$node_indices), sum)[,2]
# Now calculate the log posterior
log_post = 0.5 * ( sum(log( sigma2 / (nj*sigma2_mu + sigma2))) +
sum( (sigma2_mu* S_j^2) / (sigma2 * (nj*sigma2_mu + sigma2))))
return(log_post)
}
# Simulate_par -------------------------------------------------------------
simulate_mu = function(tree, R, sigma2, sigma2_mu) {
# Simulate mu values for a given tree
# First find which rows are terminal nodes
which_terminal = which(tree$tree_matrix[,'terminal'] == 1)
# Get node sizes for each terminal node
nj = tree$tree_matrix[which_terminal,'node_size']
# Get sum of residuals in each terminal node
sumR = aggregate(R, by = list(tree$node_indices), sum)[,2]
# Now calculate mu values
mu = rnorm(length(nj) ,
mean = (sumR / sigma2) / (nj/sigma2 + sigma2_mu),
sd = sqrt(1/(nj/sigma2 + sigma2_mu)))
# Wipe all the old mus out for other nodes
tree$tree_matrix[,'mu'] = NA
# Put in just the ones that are useful
tree$tree_matrix[which_terminal,'mu'] = mu
return(tree)
}
# Update sigma2 -------------------------------------------------------------
update_sigma2 <- function(S, n, nu, lambda){
u = 1/rgamma(1, shape = (n + nu)/2, rate = (S + nu*lambda)/2)
return(u)
}
# Update the latent variable z (MOTR-BART for classification) ---------------
update_z = function(y, prediction){
ny0 = sum(y==0)
ny1 = sum(y==1)
z = rep(NA, length(y))
z[y==0] = rtruncnorm(ny0, a = -Inf, b=0,   mean = prediction[y==0], 1)
z[y==1] = rtruncnorm(ny1, a = 0   , b=Inf, mean = prediction[y==1], 1)
return(z)
}
# Get tree priors ---------------------------------------------------------
get_tree_prior = function(tree, alpha, beta) {
# Need to work out the depth of the tree
# First find the level of each node, then the depth is the maximum of the level
level = rep(NA, nrow(tree$tree_matrix))
level[1] = 0 # First row always level 0
# Escpae quickly if tree is just a stump
if(nrow(tree$tree_matrix) == 1) {
return(log(1 - alpha)) # Tree depth is 0
}
for(i in 2:nrow(tree$tree_matrix)) {
# Find the current parent
curr_parent = as.numeric(tree$tree_matrix[i,'parent'])
# This child must have a level one greater than it's current parent
level[i] = level[curr_parent] + 1
}
# Only compute for the internal nodes
internal_nodes = which(as.numeric(tree$tree_matrix[,'terminal']) == 0)
log_prior = 0
for(i in 1:length(internal_nodes)) {
log_prior = log_prior + log(alpha) - beta * log(1 + level[internal_nodes[i]])
}
# Now add on terminal nodes
terminal_nodes = which(as.numeric(tree$tree_matrix[,'terminal']) == 1)
for(i in 1:length(terminal_nodes)) {
log_prior = log_prior + log(1 - alpha * ((1 + level[terminal_nodes[i]])^(-beta)))
}
return(log_prior)
}
get_num_cov_prior <- function(tree, lambda_cov, nu_cov, penalise_num_cov){
# Select the rows that correspond to internal nodes
which_terminal = which(tree$tree_matrix[,'terminal'] == 0)
# Get the covariates that are used to define the splitting rules
num_distinct_cov = length(unique(tree$tree_matrix[which_terminal,'split_variable']))
if (penalise_num_cov == TRUE){
if (num_distinct_cov > 0){
# A zero-truncated double Poisson
log_prior_num_cov = ddoublepois(num_distinct_cov, lambda_cov, nu_cov, log = TRUE) -
log(1-ddoublepois(0,lambda_cov, nu_cov))
} else {
log_prior_num_cov = 0
}
} else {
log_prior_num_cov = 0 # no penalisation
}
return(log_prior_num_cov)
}
x
y
sparse = FALSE
ntrees = 10
node_min_size = 5
alpha = 0.95
beta = 2
nu = 3
lambda = 0.1
mu_mu = 0
sigma2 = 1
sigma2_mu = 1
nburn = 1000
npost = 1000
nthin = 1
lambda_cov = 0.4
nu_cov = 2
penalise_num_cov = FALSE
# Extract control parameters
node_min_size = node_min_size
# Extract MCMC details
TotIter = nburn + npost*nthin # Total of iterations
# Storage containers
store_size = npost
tree_store = vector('list', store_size)
sigma2_store = rep(NA, store_size)
y_hat_store = matrix(NA, ncol = length(y), nrow = store_size)
var_count = rep(0, ncol(x))
var_count_store = matrix(0, ncol = ncol(x), nrow = store_size)
s_prob_store = matrix(0, ncol = ncol(x), nrow = store_size)
tree_fits_store = matrix(0, ncol = ntrees, nrow = length(y))
# Scale the response target variable
y_mean = mean(y)
y_sd = sd(y)
y_scale = (y - y_mean)/y_sd
n = length(y_scale)
p = ncol(x)
s = rep(1/p, p)
# Create a list of trees for the initial stump
curr_trees = create_stump(num_trees = ntrees,
y = y_scale,
X = x)
curr_trees
# Initialise the new trees as current one
new_trees = curr_trees
# Initialise the predicted values to zero
y_hat = get_predictions(curr_trees, x, single_tree = ntrees == 1)
# Set up a progress bar
pb = utils::txtProgressBar(min = 1, max = TotIter,
style = 3, width = 60,
title = 'Running rBART...')
I
i=1
j=1
current_partial_residuals = y_scale - y_hat + tree_fits_store[,j]
# Propose a new tree via grow/change/prune/swap
# type = sample(c('grow', 'prune', 'change', 'swap'), 1)
type = sample(c('grow', 'prune', 'change'), 1)
if(i < max(floor(0.1*nburn), 10)) type = 'grow' # Grow for the first few iterations
# Generate a new tree based on the current
new_trees[[j]] = update_tree(y = y_scale,
X = x,
type = type,
curr_tree = curr_trees[[j]],
node_min_size = node_min_size,
s = s)
new_trees[[j]]
s
y
# Grow_tree function ------------------------------------------------------
X = x
y = y_scale
curr_tree = curr_trees[[j]]
# Set up holder for new tree
new_tree = curr_tree
# Get the list of terminal nodes
terminal_nodes = as.numeric(which(new_tree$tree_matrix[,'terminal'] == 1))
new_tree
# Get the list of terminal nodes
terminal_nodes = as.numeric(which(new_tree$tree_matrix[,'terminal'] == 1))
terminal_nodes
# Find terminal node sizes
terminal_node_size = as.numeric(new_tree$tree_matrix[terminal_nodes,'node_size'])
terminal_node_size
available_values = NULL
max_bad_trees = 10
count_bad_trees = 0
bad_trees = TRUE
# Set up holder for new tree
new_tree = curr_tree
new_tree
# Add two extra rows to the tree in question
new_tree$tree_matrix = rbind(new_tree$tree_matrix,
c(1, NA, NA, NA, NA, NA, NA, NA), # Make sure they're both terminal
c(1, NA, NA, NA, NA, NA, NA, NA))
new_tree
terminal_nodes
terminal_node_size
node_min_size
# Choose a random terminal node to split
node_to_split = sample(terminal_nodes, 1,
prob = as.integer(terminal_node_size > node_min_size)) # Choose which node to split, set prob to zero for any nodes that are too small
node_to_split
# Choose a split variable uniformly from all columns (the first one is the intercept)
split_variable = sample(1:ncol(X), 1, prob = s)
split_variable
new_tree$node_indices
node_to_split
X[new_tree$node_indices == node_to_split,
split_variable]
# Alternatively follow BARTMachine and choose a split value using sample on the internal values of the available
available_values = sort(unique(X[new_tree$node_indices == node_to_split,
split_variable]))
available_values
resample(available_values[-c(1,length(available_values))])
# split_value = sample(available_values[-c(1,length(available_values))], 1)
split_value = resample(available_values[-c(1,length(available_values))])
new_tree
curr_parent = new_tree$tree_matrix[node_to_split, 'parent'] # Make sure to keep the current parent in there. Will be NA if at the root node
curr_parent
curr_parent = new_tree$tree_matrix[node_to_split, 'parent'] # Make sure to keep the current parent in there. Will be NA if at the root node
node_to_split
new_tree$tree_matrix[node_to_split,1:6] = c(0, # Now not temrinal
nrow(new_tree$tree_matrix) - 1, # child_left is penultimate row
nrow(new_tree$tree_matrix),  # child_right is penultimate row
curr_parent,
split_variable,
split_value)
new_tree
node_to_split
#  Fill in the parents of these two nodes
new_tree$tree_matrix[nrow(new_tree$tree_matrix),'parent'] = node_to_split
new_tree$tree_matrix[nrow(new_tree$tree_matrix)-1,'parent'] = node_to_split
new_tree
fill_tree_details(new_tree, X)
curr_tree = new_tree
curr_tree$tree_matrix
# Collect right bits of tree
tree_matrix = curr_tree$tree_matrix
# Create a new tree matrix to overwrite
new_tree_matrix = tree_matrix
# Start with dummy node indices
node_indices = rep(1, nrow(X))
node_indices
nrow(tree_matrix)
tree_matrix
i=2
as.numeric(tree_matrix[i,'parent'])
# Get the parent
curr_parent = as.numeric(tree_matrix[i,'parent'])
# Find the split variable and value of the parent
split_var = as.numeric(tree_matrix[curr_parent,'split_variable'])
split_val = as.numeric(tree_matrix[curr_parent, 'split_value'])
tree_matrix[curr_parent,'child_left']
i
node_indices
curr_parent
X[node_indices == curr_parent,split_var]
sum(X[node_indices == curr_parent,split_var] < split_val)
new_tree_matrix
# If left use less than condition
new_tree_matrix[i,'node_size'] = sum(X[node_indices == curr_parent,split_var] < split_val)
new_tree_matrix
new_tree_matrix
node_indices
node_indices[node_indices == curr_parent][X[node_indices == curr_parent,split_var] < split_val] = i
node_indices
i=3
# Get the parent
curr_parent = as.numeric(tree_matrix[i,'parent'])
curr_parent
# Find the split variable and value of the parent
split_var = as.numeric(tree_matrix[curr_parent,'split_variable'])
split_val = as.numeric(tree_matrix[curr_parent, 'split_value'])
# Find whether it's a left or right terminal node
left_or_right = ifelse(tree_matrix[curr_parent,'child_left'] == i,
'left', 'right')
new_tree_matrix
# If right use greater than condition
new_tree_matrix[i,'node_size'] = sum(X[node_indices == curr_parent,split_var] >= split_val)
node_indices[node_indices == curr_parent][X[node_indices == curr_parent,split_var] >= split_val] = i
new_tree_matrix
node_indices
new_tree = list(tree_matrix = new_tree_matrix,
node_indices = node_indices)
new_tree
# Get the list of terminal nodes
terminal_nodes = as.numeric(which(new_tree$tree_matrix[,'terminal'] == 1))
terminal_nodes
# Find terminal node sizes
terminal_node_size = as.numeric(new_tree$tree_matrix[terminal_nodes,'node_size'])
terminal_node_size
available_values = NULL
max_bad_trees = 10
count_bad_trees = 0
bad_trees = TRUE
# Add two extra rows to the tree in question
new_tree$tree_matrix = rbind(new_tree$tree_matrix,
c(1, NA, NA, NA, NA, NA, NA, NA), # Make sure they're both terminal
c(1, NA, NA, NA, NA, NA, NA, NA))
new_tree
# Choose a random terminal node to split
node_to_split = sample(terminal_nodes, 1,
prob = as.integer(terminal_node_size > node_min_size)) # Choose which node to split, set prob to zero for any nodes that are too small
node_to_split
terminal_nodes
# Choose a split variable uniformly from all columns (the first one is the intercept)
split_variable = sample(1:ncol(X), 1, prob = s)
split_variable
split_variable
X[new_tree$node_indices == node_to_split,
split_variable]
# Alternatively follow BARTMachine and choose a split value using sample on the internal values of the available
available_values = sort(unique(X[new_tree$node_indices == node_to_split,
split_variable]))
# split_value = sample(available_values[-c(1,length(available_values))], 1)
split_value = resample(available_values[-c(1,length(available_values))])
new_tree$tree_matrix[node_to_split, 'parent']
new_tree
curr_parent = new_tree$tree_matrix[node_to_split, 'parent'] # Make sure to keep the current parent in there. Will be NA if at the root node
curr_parent
new_tree$tree_matrix[node_to_split,1:6] = c(0, # Now not temrinal
nrow(new_tree$tree_matrix) - 1, # child_left is penultimate row
nrow(new_tree$tree_matrix),  # child_right is penultimate row
curr_parent,
split_variable,
split_value)
new_tree
node_to_split
#  Fill in the parents of these two nodes
new_tree$tree_matrix[nrow(new_tree$tree_matrix),'parent'] = node_to_split
new_tree$tree_matrix[nrow(new_tree$tree_matrix)-1,'parent'] = node_to_split
new_tree
# Fill_tree_details -------------------------------------------------------
curr_tree = new_tree
# Collect right bits of tree
tree_matrix = curr_tree$tree_matrix
tree_matrix
# Create a new tree matrix to overwrite
new_tree_matrix = tree_matrix
# Start with dummy node indices
node_indices = rep(1, nrow(X))
node_indices
nrow(tree_matrix)
tree_matrix
i=2
node_indices
# Get the parent
curr_parent = as.numeric(tree_matrix[i,'parent'])
curr_parent
# Find the split variable and value of the parent
split_var = as.numeric(tree_matrix[curr_parent,'split_variable'])
split_val = as.numeric(tree_matrix[curr_parent, 'split_value'])
split_var
split_val
# If left use less than condition
new_tree_matrix[i,'node_size'] = sum(X[node_indices == curr_parent,split_var] < split_val)
node_indices[node_indices == curr_parent][X[node_indices == curr_parent,split_var] < split_val] = i
new_tree_matrix
sum(X[node_indices == curr_parent,split_var] < split_val)
node_indices
# Start with dummy node indices
node_indices = rep(1, nrow(X))
node_indices
curr_parent
sum(X[node_indices == curr_parent,split_var] < split_val)
# If left use less than condition
new_tree_matrix[i,'node_size'] = sum(X[node_indices == curr_parent,split_var] < split_val)
node_indices[node_indices == curr_parent][X[node_indices == curr_parent,split_var] < split_val] = i
i=3
new_tree_matrix
# Get the parent
curr_parent = as.numeric(tree_matrix[i,'parent'])
# Find the split variable and value of the parent
split_var = as.numeric(tree_matrix[curr_parent,'split_variable'])
split_val = as.numeric(tree_matrix[curr_parent, 'split_value'])
# Find whether it's a left or right terminal node
left_or_right = ifelse(tree_matrix[curr_parent,'child_left'] == i,
'left', 'right')
# If right use greater than condition
new_tree_matrix[i,'node_size'] = sum(X[node_indices == curr_parent,split_var] >= split_val)
node_indices[node_indices == curr_parent][X[node_indices == curr_parent,split_var] >= split_val] = i
new_tree_matrix
node_indices
